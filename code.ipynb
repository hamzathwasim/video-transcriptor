{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import difflib\n",
    "from openai import OpenAI\n",
    "\n",
    "# Step 3: Extract Key Highlights using OpenAI API\n",
    "def get_key_highlights(openai_api_key, punctuated_transcript):\n",
    "    \"\"\"\n",
    "    Extract key sections of a given transcript using the OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "    - openai_api_key: API key for accessing the OpenAI API.\n",
    "    - punctuated_transcript: The punctuated version of the transcript.\n",
    "\n",
    "    Returns:\n",
    "    - List of highlights (section titles) extracted from the transcript.\n",
    "    \"\"\"\n",
    "    # Initialize the OpenAI API client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    # Send request to OpenAI API to get key highlights\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",  # Use the most recent model available\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are supposed to read and understand the provided transcript, and identify key highlights.\n",
    "                        These are section titles, so all you need to provide is section titles in chronological order. \n",
    "                        The output should be in structured JSON format with key 'highlights'.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Transcript: {punctuated_transcript}. Please return the key sections of the transcript in a structured JSON format.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract the 'content' from the response\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    # Parse the JSON response and extract highlights\n",
    "    summary_json = json.loads(content)\n",
    "    return summary_json.get('highlights', [])\n",
    "\n",
    "# Step 1: Load transcription data from JSON and text files\n",
    "def load_transcription_data(json_file_path, text_file_path):\n",
    "    \"\"\"\n",
    "    Load transcription data from a JSON file and a punctuated text file.\n",
    "\n",
    "    Parameters:\n",
    "    - json_file_path: Path to the JSON transcription file.\n",
    "    - text_file_path: Path to the punctuated text transcription file.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the JSON transcription and punctuated transcription.\n",
    "    \"\"\"\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_transcription = json.load(json_file)\n",
    "    \n",
    "    with open(text_file_path, 'r') as text_file:\n",
    "        punctuated_transcription = text_file.read()\n",
    "    \n",
    "    return json_transcription, punctuated_transcription\n",
    "\n",
    "# Step 2: Preprocess the transcripts for comparison\n",
    "def preprocess_transcripts(json_transcript, punctuated_transcript):\n",
    "    \"\"\"\n",
    "    Preprocess both the JSON and punctuated transcript into sentences.\n",
    "\n",
    "    Parameters:\n",
    "    - json_transcript: JSON format transcript with time and duration data.\n",
    "    - punctuated_transcript: Punctuated text version of the transcript.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing processed JSON sentences and punctuated sentences.\n",
    "    \"\"\"\n",
    "    # Tokenize punctuated transcription into sentences\n",
    "    punctuated_sentences = punctuated_transcript.splitlines()\n",
    "    \n",
    "    # Clean up the JSON transcript and add timing information\n",
    "    json_sentences = [{'text': entry['text'].strip(), \n",
    "                       'start_time': entry['offset'] / 1000.0, \n",
    "                       'end_time': (entry['offset'] + entry['duration']) / 1000.0}\n",
    "                      for entry in json_transcript]\n",
    "    \n",
    "    return json_sentences, punctuated_sentences\n",
    "\n",
    "# Step 5: Find best match for a given highlight and map to timestamps\n",
    "def find_best_match(summary_sentence, json_sentences, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Find the best matching sentence for a given highlight using sequence matching.\n",
    "\n",
    "    Parameters:\n",
    "    - summary_sentence: A sentence from the highlights.\n",
    "    - json_sentences: List of sentences with timestamps from the JSON transcript.\n",
    "    - threshold: Minimum match ratio to consider a match valid.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing start time, end time, and confidence score for the match.\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    highest_ratio = 0\n",
    "\n",
    "    # Compare the highlight with all sentences in the JSON transcript\n",
    "    for entry in json_sentences:\n",
    "        match_ratio = difflib.SequenceMatcher(None, summary_sentence.lower(), entry['text'].lower()).ratio()\n",
    "        if match_ratio > highest_ratio:\n",
    "            highest_ratio = match_ratio\n",
    "            best_match = entry\n",
    "    \n",
    "    # If the highest match ratio exceeds the threshold, return the matched entry\n",
    "    if highest_ratio > threshold and best_match:\n",
    "        return {\n",
    "            'start_time': best_match['start_time'],\n",
    "            'end_time': best_match['end_time'],\n",
    "            'confidence': round(highest_ratio, 2)\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Step 5 (Updated): Match highlights to timestamps from the list\n",
    "def match_summary_to_timestamps_from_list(highlights_list, json_sentences):\n",
    "    \"\"\"\n",
    "    Match each highlight to its best-matching sentence in the JSON transcript.\n",
    "\n",
    "    Parameters:\n",
    "    - highlights_list: List of highlight sentences.\n",
    "    - json_sentences: List of JSON sentences with timestamps.\n",
    "\n",
    "    Returns:\n",
    "    - List of matched highlights with their corresponding timestamps and confidence scores.\n",
    "    \"\"\"\n",
    "    matched_highlights = []\n",
    "    \n",
    "    # Match each highlight to the best JSON sentence\n",
    "    for highlight in highlights_list:\n",
    "        best_match = find_best_match(highlight, json_sentences)\n",
    "        if best_match:\n",
    "            matched_highlights.append({\n",
    "                \"highlight\": highlight,\n",
    "                \"start_time\": best_match['start_time'],\n",
    "                \"end_time\": best_match['end_time'],\n",
    "                \"confidence\": best_match['confidence']\n",
    "            })\n",
    "    \n",
    "    return matched_highlights\n",
    "\n",
    "# Step 6: Main function to orchestrate the process\n",
    "def generate_video_highlights(json_file_path, text_file_path, openai_api_key=None, highlights=None):\n",
    "    \"\"\"\n",
    "    Generate video highlights by loading transcripts, processing them, and optionally using OpenAI API to extract highlights.\n",
    "\n",
    "    Parameters:\n",
    "    - json_file_path: Path to the JSON transcription file.\n",
    "    - text_file_path: Path to the punctuated transcription file.\n",
    "    - openai_api_key: API key for accessing OpenAI API (optional).\n",
    "    - highlights: Predefined list of highlights (optional).\n",
    "\n",
    "    Returns:\n",
    "    - Matched highlights with timestamps if available.\n",
    "    \"\"\"\n",
    "    # Load transcription data\n",
    "    json_transcript, punctuated_transcript = load_transcription_data(json_file_path, text_file_path)\n",
    "    \n",
    "    # Preprocess transcripts\n",
    "    json_sentences, punctuated_sentences = preprocess_transcripts(json_transcript, punctuated_transcript)\n",
    "    \n",
    "    # If no highlights are provided, use the OpenAI API to generate them\n",
    "    if openai_api_key and not highlights:\n",
    "        highlights = get_key_highlights(openai_api_key, punctuated_transcript)\n",
    "    \n",
    "    # If highlights are available, match them to the timestamps\n",
    "    if highlights:\n",
    "        matched_highlights = match_summary_to_timestamps_from_list(highlights, json_sentences)\n",
    "        return matched_highlights\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No highlights available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file paths and API key\n",
    "json_file = 'transcript.json'  # Path to the JSON transcription file\n",
    "text_file = 'transcript.txt'   # Path to the punctuated text transcription file\n",
    "openai_api_key = ''\n",
    "\n",
    "# Step 4: Optionally get key highlights using OpenAI API\n",
    "matched_highlights = generate_video_highlights(json_file, text_file, openai_api_key=openai_api_key)\n",
    "\n",
    "# Output the matched highlights with timestamps\n",
    "if matched_highlights:\n",
    "    print(json.dumps(matched_highlights, indent=2))\n",
    "else:\n",
    "    print(\"No highlights available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
